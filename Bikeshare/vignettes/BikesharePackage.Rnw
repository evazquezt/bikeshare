\documentclass{article}
%\VignetteIndexEntry{Using Bikeshare}
\begin{document}
\SweaveOpts{concordance=TRUE}

\title{The Bikeshare Package}
\author{Sara Kwasnick and John Sears}
\maketitle

\section{Motivation}
The Bikeshare package is designed to aid social science research into municipal bike-sharing programs.  Benefits of use are streamlined data loading (with out-of-the-box support for many cities), graphical data exploration via integration with Google Maps API, and geographic data manipulation such as car versus bike distance calculation.

Our goal is that this package dramatically reduces the start-up costs of engaging in data-driven research of municipal bikeshare systems. 

We loosely group our functionality into three functional groups: 
\begin{itemize}
\item[1.] Ease of data loading and cleaning
\item[2.] Numerical analysis via cutting-edge graph algorithms
\item[3.] Powerful visualization tools leveraging the Google Maps API
\end{itemize}
To illustrate the utility of the \texttt{Bikeshare} package, we will run through a typical use-case scenario based on publicly available data from Capital Bikeshare in Washington, DC.

\section{Loading the Data}
Bikeshare data typically comprises two data files: a list of stations and a list of data on individual trips.  The two datasets are tied together by station ID numbers.  In addition to station IDs, the station data contains: station name, latitude, longitude, number of bike spaces, installation date and removal date, if applicable. The trips data contains: start times, end times, start location, end location, bike ID number, and member type (for example, subscribers vs. one-time users).

The Bikeshare Package comes equipped with Q4 2010 data from Capital Bikeshare pre-loaded as a test dataset.  We load the station data as follows:
<<>>=
library(Bikeshare)
## Load station data.
stations = readStationData(system.file("extData/bikeStations.xml",
                    package="Bikeshare"),.cities()$WAS)
## Load trip data
bd = readTripData(system.file("extData/2010-4th-quarter.csv", 
                    package="Bikeshare"), .cities()$WAS, stations)
@
Note that for every city supported by the \texttt{Bikeshare} Package, we define an S4 BikeshareCity object accessible using \texttt{.cities()}.  All data cleaning is done behind the scenes. What we have now is a list of BikeshareStation objects containig station-level data and a BikeshareData object that wraps all of the trip data.  These two objects will constitute the working unit of analysis.

\section{Graphics}
At this point the data is ready for analysis.  Before developing any models, we gain insight into the data's structure using \texttt{Bikeshare}'s built-in visualization tools.  We can begin by simply viewing the locations of all stations in our dataset.
<<fig=TRUE>>=
plotStations(stations)
@

As we can see, the stations tend to be clustered in Northern Virginia and Northwest DC, and the topology of the landscape (visible on the map) appears to influence station location.  Next, we narrow our focus to only look at stations that are within a two kilometer bike ride of the station at Dupont Circle, station 31200.  To get a sense of the usage rates at each station, we use the \texttt{plotBubbles} tool.

<<fig=TRUE>>=
## Uses best biking path result from Google Maps API
#distances <- as.data.frame(t(getDistance(stations,fromSubset="stationId==31200",
#                        mode="bicycling")))
#closeStations <- (distances[,1] <= 3) | (rownames(distances)=="31200")
distances <- 20*runif(313)  ## until I can do queries again :\
closeStations <- distances <= 3
plotBubbles(bd, stationSubset=closeStations,zoom=14,alpha=.5)
@

To get a sense of which routes are most frequent amongst the stations within a 3 km ride of the Dupont Circle station, we can use the \texttt{plotTrips} function.

<<fig=TRUE>>=
plotTrips(bd,stationSubset=closeStations,zoom=14,alpha=.5)
@

\section{Analysis}
Now let's try some simple analysis.  First, suppose we wanted to install a new station.  One way to get a sense of demand for that station is to look at the current usage rates of stations as a function of the proximity to- and attributes of- the next nearest station, controlling for number of bikes.  Of course we would also want to factor in outside data like zoning and population of the location, but in general this will give us a rough sense of what demand might be like at a new station.

For simplicity, we'll limit ourselves to stations in the \texttt{closeStations} subset.  

<<>>=
library(geosphere)
stationDF <- subset(makeStationDataFrame(stations),closeStations)
distMat <- distm(stationDF[,c("long","lat")])/1000 + 1e10*diag(dim(stationDF)[1])
closest <- apply(distMat,1,which.min)
stationDF$closestIndex <- closest

## Add a column to stationDF containing distance to the nearest station
index <- matrix(c(1:dim(distMat)[1],closest),ncol=2)
stationDF$closestStation <- distMat[index]

## Add a column to stationDF containing number of bikes at nearest station
stationDF$closestNumBikes <- stationDF$numBikes[closest]

## Add a column to stationDF containing total visits to station and total visits to closest station
totalVisits <- getTotalVisits(bd,stationSubset=closeStations)
names(totalVisits)[1] <- "stationId"
stationDF <- merge(stationDF,totalVisits)
stationDF$closestVisits <- stationDF$visits[closest]

## Try some simple linear models
model <- lm(visits ~ closestStation + closestNumBikes + closestVisits + numBikes,data=stationDF)
model <- lm(visits ~ closestVisits + closestStation,data=stationDF)
model <- lm(visits ~ closestStation,data=stationDF) ## something like this? easy...
summary(model)
@
In general, we can regress usage of station on distance of nearest n stations to try to predict demand at a new station.


\end{document}